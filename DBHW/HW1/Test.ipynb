{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# # Connect to mysql\n",
    "# # Input: dbname\n",
    "# # Output: con obj, cursor obj\n",
    "#######################################################################\n",
    "IP = \"s.snu.ac.kr\"\n",
    "ID = \"ADB2018_26190\"\n",
    "PW = \"ADB2018_26190\"\n",
    "DBase = \"ADB2018_26190\"\n",
    "import pymysql.cursors\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math \n",
    "\n",
    "con = pymysql.connect(host = IP, \n",
    "                            user = ID,\n",
    "                            password = PW,\n",
    "                            db = DBase,\n",
    "                            charset = 'utf8mb4')\n",
    "# con = pymysql.connect(host = 'localhost', \n",
    "#                             user = 'root',\n",
    "#                             password = 'root',\n",
    "#                             db = dbname,\n",
    "#                             charset = 'utf8mb4')\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Database</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>information_schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADB2018_26190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Database\n",
       "0  information_schema\n",
       "1       ADB2018_26190"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"show databases\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tables_in_ADB2018_26190</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>InvertedIndex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wiki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tables_in_ADB2018_26190\n",
       "0           InvertedIndex\n",
       "1                    link\n",
       "2                    wiki"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"show tables\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql(\"select * from wiki\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql(\"select * from link\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tables...\n"
     ]
    }
   ],
   "source": [
    "print(\"building tables...\")\n",
    "\n",
    "# # Before executing this file, create wiki, link table in DBase using mysql-workbench  \n",
    "#######################################################################\n",
    "# # Make inverted index table \n",
    "# # Input: wiki table \n",
    "# # Output: InvertedIndex table(term, id, title, freq)\n",
    "#######################################################################\n",
    "sql = \"select * from wiki\"\n",
    "cursor.execute(sql)\n",
    "result_wiki = cursor.fetchall()\n",
    "\n",
    "sql = \"select count(*) from information_schema.tables where (table_schema = %s) and (table_name = %s)\"\n",
    "cursor.execute(sql, (DBase, \"InvertedIndex\"))\n",
    "\n",
    "if cursor.fetchall()[0][0] == 0: \n",
    "    # Create inverted index table \n",
    "    sql = \"create table InvertedIndex (term varchar(255) not null, id int(11) not null, freq int(11) not null)\"\n",
    "    cursor.execute(sql)\n",
    "    # # Clean inverted index table\n",
    "    # sql = \"delete from InvertedIndex\" \n",
    "    # cursor.execute(sql)\n",
    "\n",
    "    # insertion from wiki table \n",
    "    sql = \"insert into InvertedIndex (term,id,freq) values (%s,%s,%s)\"\n",
    "    for Doc in result_wiki:\n",
    "    #     print(type(Doc)) #tuple (id, doc_name, doc_script)\n",
    "        tokens = nltk.word_tokenize(Doc[2].lower())\n",
    "        fdist = nltk.FreqDist(tokens) # dictionary {term:freq, ... }\n",
    "        for term, freq in fdist.items():\n",
    "            cursor.execute(sql,(term, Doc[0], freq))\n",
    "    #     print(fdist)\n",
    "    con.commit()\n",
    "    \n",
    "#cursor.execute(\"drop table InvertedIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready to search...\n"
     ]
    }
   ],
   "source": [
    "print(\"ready to search...\")\n",
    "#######################################################################\n",
    "# # PageRank Score Calculation\n",
    "# # Input: link table \n",
    "# # Output: PageRank list R(id, PageRank score)\n",
    "#######################################################################\n",
    "# print(\"calculating pagerank score ...\")\n",
    "import numpy as np\n",
    "# Get Ni for each\n",
    "sql = \"select id_from, count(*) as outgoing from link group by id_from order by id_from\"\n",
    "cursor.execute(sql)\n",
    "FromNiInfo = cursor.fetchall()\n",
    "\n",
    "Ni_dict = {}\n",
    "for idx, FromNi in enumerate(FromNiInfo):\n",
    "#     print(FromNi[0], FromNi[1])\n",
    "    id_from = FromNi[0]\n",
    "    Ni = FromNi[1]\n",
    "    Ni_dict[id_from] = Ni\n",
    "\n",
    "# Get N and id_all(sorted order) \n",
    "sql = \"select distinct id_from from link order by id_from\"\n",
    "cursor.execute(sql)\n",
    "SetOfFromInfo = cursor.fetchall()\n",
    "\n",
    "sql = \"select distinct id_to from link order by id_to\"\n",
    "cursor.execute(sql)\n",
    "SetOfToInfo = cursor.fetchall()\n",
    "\n",
    "SetOfFrom = set()\n",
    "SetOfTo = set()\n",
    "\n",
    "for idx, From in enumerate(SetOfFromInfo):\n",
    "#     print(type(From[0]))\n",
    "    SetOfFrom.add(From[0])\n",
    "    \n",
    "for idx, To in enumerate(SetOfToInfo):\n",
    "#     print(type(From[0]))\n",
    "    SetOfTo.add(To[0])\n",
    "    \n",
    "id_all = sorted(SetOfFrom.union(SetOfTo))\n",
    "N = len(id_all)\n",
    "\n",
    "# Get N_idx and N_idx_inverse; it means dictionary[Doc.id] = index of Transition Matrix or State Matrix    \n",
    "N_idx = {}\n",
    "N_idx_inverse = {}\n",
    "for idInfo, idx in enumerate(id_all):\n",
    "#     print(idx, idInfo)\n",
    "    N_idx[idx] = idInfo\n",
    "    N_idx_inverse[idInfo] = idx\n",
    "\n",
    "# Get SateMatrix S; check whether existing from j to i link  \n",
    "S = np.zeros((N,N)) # from j to i info : S[i][j]\n",
    "sql = \"select * from link order by id_from\"\n",
    "cursor.execute(sql)\n",
    "FromToInfo = np.array(cursor.fetchall())\n",
    "for fromto in FromToInfo:\n",
    "    id_to = fromto[1]\n",
    "    id_from = fromto[0]\n",
    "    S[N_idx[id_to]][N_idx[id_from]] = 1\n",
    "\n",
    "# Get Transition Matrix M and Score Vector R \n",
    "M = np.zeros((N,N)) # from j to i info : M[i][j]\n",
    "for _, id_from in enumerate(sorted(SetOfFrom)):\n",
    "    for _, id_to in enumerate(id_all):\n",
    "        # if link id_from to id_to exists\n",
    "        if S[N_idx[id_to]][N_idx[id_from]] != 0:\n",
    "            M[N_idx[id_to]][N_idx[id_from]] = 1/Ni_dict[id_from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 ...\n",
      "distance =  74.10893977199761\n",
      "iteration 1 ...\n",
      "distance =  19.654939936357895\n",
      "iteration 2 ...\n",
      "distance =  1.317147357409797\n",
      "iteration 3 ...\n",
      "distance =  0.16673183038197417\n",
      "iteration 4 ...\n",
      "distance =  0.023230458923275472\n",
      "iteration 5 ...\n",
      "distance =  0.00363864354638029\n",
      "iteration 6 ...\n",
      "distance =  0.0005172302450978651\n",
      "iteration 7 ...\n",
      "distance =  8.159564757324994e-05\n",
      "iteration 8 ...\n",
      "distance =  1.1621562302864015e-05\n",
      "iteration 9 ...\n",
      "distance =  1.8351128469182678e-06\n",
      "iteration 10 ...\n",
      "distance =  2.615057805869916e-07\n",
      "iteration 11 ...\n",
      "distance =  4.129248301639776e-08\n",
      "iteration 12 ...\n",
      "distance =  5.885459257455751e-09\n"
     ]
    }
   ],
   "source": [
    "# PageRank Algorithm\n",
    "# Input: Station Matrix S, Transition Matrix T, RankVector R \n",
    "# Output: updated RankVector R \n",
    "delta = 0.15\n",
    "elipslion = 1e-8\n",
    "# R = np.ones((N,1))*(1/N)\n",
    "R = np.ones((N,1))\n",
    "K = np.ones((N,1))*(delta/N)\n",
    "# R = delta * np.matmul(M,prevR) + K\n",
    "iteration = 0\n",
    "distance = 100\n",
    "while distance > elipslion:\n",
    "    print(\"iteration\", iteration, \"...\")\n",
    "    prevR = R\n",
    "    R = delta * np.matmul(M,R) + K\n",
    "    iteration = iteration + 1\n",
    "    distance = np.linalg.norm(R-prevR)\n",
    "    print(\"distance = \",np.linalg.norm(R-prevR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-26190>my sql\n",
      "id        title                                             TF-IDF              PageRank            \n",
      "2726686   Headfirst_for_Halos                                 2.95e-04            2.34e-05          \n",
      "46786015  Quaglino%27s                                        1.96e-04            2.69e-05          \n",
      "23936083  Sunshine_and_Rain                                   1.93e-04            2.69e-05          \n",
      "7026696   Se_piangi%2C_se_ridi                                1.80e-04            2.34e-05          \n",
      "3574725   Bianca_Montgomery                                   1.10e-04            2.34e-05          \n",
      "37023144  Jane_Chambers                                       1.00e-04            2.34e-05          \n",
      "5703855   STV_Edinburgh                                       7.07e-05            2.76e-05          \n",
      "416890    Chris_Coleman_(footballer)                          4.87e-05            3.05e-05          \n",
      "15072489  Carrere_Records                                     5.39e-05            2.69e-05          \n",
      "41007183  Thigh_gap                                           6.11e-05            2.34e-05          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get input from console\n",
    "print(\"2018-26190>\",end = '')\n",
    "query = input()\n",
    "if query == \"exit()\":\n",
    "    print(\"end\")\n",
    "querys = query.lower().split()\n",
    "#######################################################################\n",
    "# # TF-IDF Score calculation\n",
    "# # Input: InvertedIndex table, wiki table, query(string)\n",
    "# # Output: TF-IDF list TFIDF(id, title, TF-IDF score) \n",
    "#######################################################################\n",
    "def TFIDFscore(Nd, Ndt, Nt):\n",
    "        return math.log1p(Ndt/Nd)*(1/Nt)\n",
    "\n",
    "TFIDFs_idx = {}\n",
    "TFIDFs_idx_inverse = {}\n",
    "TFIDFs = []\n",
    "iteration = 0\n",
    "for query in querys:\n",
    "    #######################################################################\n",
    "    # # TF-IDF Score calculation for each word \n",
    "    #######################################################################\n",
    "    sql = \"select sum(freq),id from InvertedIndex where id in (select id from InvertedIndex where term = %s) group by id order by id\"\n",
    "    cursor.execute(sql,query)\n",
    "    NdInfo = cursor.fetchall()\n",
    "\n",
    "    sql = \"select freq, id, term from InvertedIndex where term = %s order by id\"\n",
    "    cursor.execute(sql,query)\n",
    "    NdtInfo = cursor.fetchall()\n",
    "\n",
    "    sql = \"select count(*) from InvertedIndex where term = %s\"\n",
    "    cursor.execute(sql,query)\n",
    "    Nt = cursor.fetchall()[0][0]\n",
    "    \n",
    "    TFIDF = []\n",
    "    for i in range(len(NdtInfo)):\n",
    "        if NdInfo[i][1] == NdtInfo[i][1]:\n",
    "            Nd = NdInfo[i][0]\n",
    "            Ndt = NdtInfo[i][0]\n",
    "            id = NdInfo[i][1]\n",
    "    #         print(id,\" \",math.log1p(Ndt/Nd)*(1/Nt))\n",
    "    #         TFIDF.append((id, math.log1p(Ndt/Nd)*(1/Nt)))\n",
    "            TFIDF.append((id, TFIDFscore(Nd, Ndt, Nt)))\n",
    "    TFIDFs.append(TFIDF)\n",
    "    TFIDFs_idx[query] = iteration\n",
    "    TFIDFs_idx_inverse[iteration] = query\n",
    "    iteration = iteration + 1\n",
    "    \n",
    "# Get title dictionary     \n",
    "sql = \"select id,title from wiki order by id\"\n",
    "cursor.execute(sql)\n",
    "id_title = cursor.fetchall()\n",
    "id_title_dictionary = {}\n",
    "for _, idtitle in enumerate(id_title):\n",
    "    v_id = idtitle[0]\n",
    "    v_title = idtitle[1]\n",
    "    id_title_dictionary[v_id] = v_title\n",
    "\n",
    "# Union TFIDFs\n",
    "TFIDFsetlist = []      \n",
    "for query in querys:\n",
    "    temp = np.array(TFIDFs[TFIDFs_idx[query]])\n",
    "    if len(temp) == 0:\n",
    "        idsForOneQuery = temp.astype(int)\n",
    "    else:\n",
    "        idsForOneQuery = temp[...,0].astype(int)\n",
    "    TFIDFsetlist.append(set(idsForOneQuery))\n",
    "\n",
    "UnionId = []\n",
    "UnionId_idx = {}\n",
    "UnionId_idx_inverse = {}\n",
    "for TFIDFset in TFIDFsetlist:\n",
    "    UnionId = list(set(UnionId)|set(TFIDFset))\n",
    "\n",
    "UnionId.sort()\n",
    "iteration = 0;\n",
    "for idvalue in UnionId:\n",
    "    UnionId_idx[idvalue] = iteration\n",
    "    UnionId_idx_inverse[iteration] = idvalue\n",
    "    iteration = iteration + 1\n",
    "    \n",
    "# Get TFIDF Score Matrix SM\n",
    "SM = np.zeros((len(querys), len(UnionId)))\n",
    "for row in range(len(querys)):\n",
    "    LenOfcols = len(TFIDFs[row])\n",
    "#     print(LenOfcols)\n",
    "    for j in range(LenOfcols): # j means each query's index of id\n",
    "#         print(TFIDFs[row][j][0], TFIDFs[0][j][1], TFIDFs[0][j][2])  # \n",
    "        col = UnionId_idx[TFIDFs[row][j][0]]\n",
    "#         title = TFIDFs[row][j][1]\n",
    "        score = TFIDFs[row][j][1]\n",
    "        SM[row][col] = score\n",
    "# SM\n",
    "\n",
    "#######################################################################\n",
    "# # Get Top K list\n",
    "# # Input: TFIDF Score Matrix SM, PageRank list R\n",
    "# # Output: QAList(sorted order by TFIDF score * PageRank score)\n",
    "#######################################################################\n",
    "QAList = []\n",
    "for it in UnionId_idx:\n",
    "    Id = it\n",
    "    UnionTFIDFScore = SM[...,UnionId_idx[it]].sum()\n",
    "    Uniontitle = id_title_dictionary[it] \n",
    "    PrankScore = R[N_idx[Id]][0]\n",
    "    QAList.append((Id, Uniontitle, UnionTFIDFScore, PrankScore))\n",
    "    \n",
    "def SortCriteria(item):\n",
    "    return item[2]*item[3]\n",
    "QAList.sort(key= SortCriteria, reverse= True)\n",
    "\n",
    "strFormat = '%-10s%-50s%-20s%-20s\\n'\n",
    "strOut = strFormat % ('id', 'title', 'TF-IDF', 'PageRank')\n",
    "iteration = 0;\n",
    "for ans in QAList:\n",
    "    if iteration < 10:\n",
    "#         print(ans[0], ans[1], ans[2], ans[3])\n",
    "        strOut += strFormat %(ans[0], ans[1], format(ans[2],\"10.2e\"), format(ans[3],\"10.2e\"))\n",
    "    else:\n",
    "       break\n",
    "    iteration = iteration + 1\n",
    "    \n",
    "print(strOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
