{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "#######################################################################\n",
    "# # Connect to mysql\n",
    "# # Output: con obj, cursor obj\n",
    "#######################################################################\n",
    "IP = \"s.snu.ac.kr\"\n",
    "ID = \"ADB2018_26190\"\n",
    "PW = \"ADB2018_26190\"\n",
    "DBase = \"ADB2018_26190\"\n",
    "import pymysql.cursors\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math \n",
    "\n",
    "con = pymysql.connect(host = IP, \n",
    "                            user = ID,\n",
    "                            password = PW,\n",
    "                            db = DBase,\n",
    "                            charset = 'utf8mb4')\n",
    "# con = pymysql.connect(host = 'localhost', \n",
    "#                             user = 'root',\n",
    "#                             password = 'root',\n",
    "#                             db = dbname,\n",
    "#                             charset = 'utf8mb4')\n",
    "cursor = con.cursor()\n",
    "\n",
    "print(\"building tables...\")\n",
    "# # Before executing this file, create wiki, link table in DBase using mysql-workbench  \n",
    "#######################################################################\n",
    "# # Make inverted index table \n",
    "# # Input: wiki table \n",
    "# # Output: InvertedIndex table(term, id, title, freq)\n",
    "#######################################################################\n",
    "sql = \"select * from wiki\"\n",
    "cursor.execute(sql)\n",
    "result_wiki = cursor.fetchall()\n",
    "\n",
    "sql = \"select count(*) from information_schema.tables where (table_schema = %s) and (table_name = %s)\"\n",
    "cursor.execute(sql, (DBase, \"InvertedIndex\"))\n",
    "\n",
    "if cursor.fetchall()[0][0] == 0: \n",
    "    # Create inverted index table \n",
    "    sql = \"create table InvertedIndex (term varchar(255) not null, id int(11) not null, freq int(11) not null)\"\n",
    "    cursor.execute(sql)\n",
    "    # # Clean inverted index table\n",
    "    # sql = \"delete from InvertedIndex\" \n",
    "    # cursor.execute(sql)\n",
    "\n",
    "    # insertion from wiki table \n",
    "    sql = \"insert into InvertedIndex (term,id,freq) values (%s,%s,%s)\"\n",
    "    for Doc in result_wiki:\n",
    "    #     print(type(Doc)) #tuple (id, doc_name, doc_script)\n",
    "        tokens = nltk.word_tokenize(Doc[2].lower())\n",
    "        fdist = nltk.FreqDist(tokens) # dictionary {term:freq, ... }\n",
    "        for term, freq in fdist.items():\n",
    "            cursor.execute(sql,(term, Doc[0], freq))\n",
    "    #     print(fdist)\n",
    "    con.commit()\n",
    "    \n",
    "#cursor.execute(\"drop table InvertedIndex\")\n",
    "\n",
    "print(\"ready to search...\")\n",
    "#######################################################################\n",
    "# # PageRank Score Calculation\n",
    "# # Input: link table \n",
    "# # Output: PageRank list R(id, PageRank score)\n",
    "#######################################################################\n",
    "# print(\"calculating pagerank score ...\")\n",
    "import numpy as np\n",
    "# Get Ni for each\n",
    "sql = \"select id_from, count(*) as outgoing from link group by id_from order by id_from\"\n",
    "cursor.execute(sql)\n",
    "FromNiInfo = cursor.fetchall()\n",
    "\n",
    "Ni_dict = {}\n",
    "for idx, FromNi in enumerate(FromNiInfo):\n",
    "#     print(FromNi[0], FromNi[1])\n",
    "    id_from = FromNi[0]\n",
    "    Ni = FromNi[1]\n",
    "    Ni_dict[id_from] = Ni\n",
    "\n",
    "# Get N and id_all(sorted order) \n",
    "sql = \"select distinct id_from from link order by id_from\"\n",
    "cursor.execute(sql)\n",
    "SetOfFromInfo = cursor.fetchall()\n",
    "\n",
    "sql = \"select distinct id_to from link order by id_to\"\n",
    "cursor.execute(sql)\n",
    "SetOfToInfo = cursor.fetchall()\n",
    "\n",
    "SetOfFrom = set()\n",
    "SetOfTo = set()\n",
    "\n",
    "for idx, From in enumerate(SetOfFromInfo):\n",
    "#     print(type(From[0]))\n",
    "    SetOfFrom.add(From[0])\n",
    "    \n",
    "for idx, To in enumerate(SetOfToInfo):\n",
    "#     print(type(From[0]))\n",
    "    SetOfTo.add(To[0])\n",
    "    \n",
    "id_all = sorted(SetOfFrom.union(SetOfTo))\n",
    "N = len(id_all)\n",
    "\n",
    "# Get N_idx and N_idx_inverse; it means dictionary[Doc.id] = index of Transition Matrix or State Matrix    \n",
    "N_idx = {}\n",
    "N_idx_inverse = {}\n",
    "for idInfo, idx in enumerate(id_all):\n",
    "#     print(idx, idInfo)\n",
    "    N_idx[idx] = idInfo\n",
    "    N_idx_inverse[idInfo] = idx\n",
    "\n",
    "# Get SateMatrix S; check whether existing from j to i link  \n",
    "S = np.zeros((N,N)) # from j to i info : S[i][j]\n",
    "sql = \"select * from link order by id_from\"\n",
    "cursor.execute(sql)\n",
    "FromToInfo = np.array(cursor.fetchall())\n",
    "for fromto in FromToInfo:\n",
    "    id_to = fromto[1]\n",
    "    id_from = fromto[0]\n",
    "    S[N_idx[id_to]][N_idx[id_from]] = 1\n",
    "\n",
    "# Get Transition Matrix M and Score Vector R \n",
    "M = np.zeros((N,N)) # from j to i info : M[i][j]\n",
    "for _, id_from in enumerate(sorted(SetOfFrom)):\n",
    "    for _, id_to in enumerate(id_all):\n",
    "        # if link id_from to id_to exists\n",
    "        if S[N_idx[id_to]][N_idx[id_from]] != 0:\n",
    "            M[N_idx[id_to]][N_idx[id_from]] = 1/Ni_dict[id_from]\n",
    "\n",
    "# PageRank Algorithm\n",
    "# Input: Station Matrix S, Transition Matrix T, RankVector R \n",
    "# Output: updated RankVector R \n",
    "delta = 0.15\n",
    "elipslion = 1e-8\n",
    "# R = np.ones((N,1))*(1/N)\n",
    "R = np.ones((N,1))\n",
    "K = np.ones((N,1))*(delta/N)\n",
    "# R = delta * np.matmul(M,prevR) + K\n",
    "iteration = 0\n",
    "distance = 100\n",
    "while distance > elipslion:\n",
    "#     print(\"iteration\", iteration, \"...\")\n",
    "    prevR = R\n",
    "    R = delta * np.matmul(M,R) + K\n",
    "    iteration = iteration + 1\n",
    "    distance = np.linalg.norm(R-prevR)\n",
    "#     print(\"distance = \",np.linalg.norm(R-prevR))\n",
    "\n",
    "#######################################################################\n",
    "# # TF-IDF Score calculation\n",
    "# # Input: InvertedIndex table, wiki table, query(string)\n",
    "# # Output: TF-IDF list TFIDF(id, title, TF-IDF score) \n",
    "#######################################################################\n",
    "def TFIDFscore(Nd, Ndt, Nt):\n",
    "        return math.log1p(Ndt/Nd)*(1/Nt)\n",
    "while True:\n",
    "    \n",
    "    # Get input from console\n",
    "    print(\"2018-26190>\",end = '')\n",
    "    query = input()\n",
    "    if query == \"exit()\":\n",
    "        break\n",
    "    querys = query.lower().split()\n",
    "    \n",
    "    TFIDFs_idx = {}\n",
    "    TFIDFs_idx_inverse = {}\n",
    "    TFIDFs = []\n",
    "    iteration = 0\n",
    "    for query in querys:\n",
    "        #######################################################################\n",
    "        # # TF-IDF Score calculation for each word \n",
    "        #######################################################################\n",
    "        sql = \"select sum(freq),id from InvertedIndex where id in (select id from InvertedIndex where term = %s) group by id order by id\"\n",
    "        cursor.execute(sql,query)\n",
    "        NdInfo = cursor.fetchall()\n",
    "\n",
    "        sql = \"select freq, id, term from InvertedIndex where term = %s order by id\"\n",
    "        cursor.execute(sql,query)\n",
    "        NdtInfo = cursor.fetchall()\n",
    "\n",
    "        sql = \"select count(*) from InvertedIndex where term = %s\"\n",
    "        cursor.execute(sql,query)\n",
    "        Nt = cursor.fetchall()[0][0]\n",
    "\n",
    "        TFIDF = []\n",
    "        for i in range(len(NdtInfo)):\n",
    "            if NdInfo[i][1] == NdtInfo[i][1]:\n",
    "                Nd = NdInfo[i][0]\n",
    "                Ndt = NdtInfo[i][0]\n",
    "                id = NdInfo[i][1]\n",
    "        #         print(id,\" \",math.log1p(Ndt/Nd)*(1/Nt))\n",
    "        #         TFIDF.append((id, math.log1p(Ndt/Nd)*(1/Nt)))\n",
    "                TFIDF.append((id, TFIDFscore(Nd, Ndt, Nt)))\n",
    "        TFIDFs.append(TFIDF)\n",
    "        TFIDFs_idx[query] = iteration\n",
    "        TFIDFs_idx_inverse[iteration] = query\n",
    "        iteration = iteration + 1\n",
    "\n",
    "    # Get title dictionary     \n",
    "    sql = \"select id,title from wiki order by id\"\n",
    "    cursor.execute(sql)\n",
    "    id_title = cursor.fetchall()\n",
    "    id_title_dictionary = {}\n",
    "    for _, idtitle in enumerate(id_title):\n",
    "        v_id = idtitle[0]\n",
    "        v_title = idtitle[1]\n",
    "        id_title_dictionary[v_id] = v_title\n",
    "\n",
    "    # Union TFIDFs\n",
    "    TFIDFsetlist = []      \n",
    "    for query in querys:\n",
    "        temp = np.array(TFIDFs[TFIDFs_idx[query]])\n",
    "        if len(temp) == 0:\n",
    "            idsForOneQuery = temp.astype(int)\n",
    "        else:\n",
    "            idsForOneQuery = temp[...,0].astype(int)\n",
    "        TFIDFsetlist.append(set(idsForOneQuery))\n",
    "\n",
    "    UnionId = []\n",
    "    UnionId_idx = {}\n",
    "    UnionId_idx_inverse = {}\n",
    "    for TFIDFset in TFIDFsetlist:\n",
    "        UnionId = list(set(UnionId)|set(TFIDFset))\n",
    "\n",
    "    UnionId.sort()\n",
    "    iteration = 0;\n",
    "    for idvalue in UnionId:\n",
    "        UnionId_idx[idvalue] = iteration\n",
    "        UnionId_idx_inverse[iteration] = idvalue\n",
    "        iteration = iteration + 1\n",
    "\n",
    "    # Get TFIDF Score Matrix SM\n",
    "    SM = np.zeros((len(querys), len(UnionId)))\n",
    "    for row in range(len(querys)):\n",
    "        LenOfcols = len(TFIDFs[row])\n",
    "    #     print(LenOfcols)\n",
    "        for j in range(LenOfcols): # j means each query's index of id\n",
    "    #         print(TFIDFs[row][j][0], TFIDFs[0][j][1], TFIDFs[0][j][2])  # \n",
    "            col = UnionId_idx[TFIDFs[row][j][0]]\n",
    "    #         title = TFIDFs[row][j][1]\n",
    "            score = TFIDFs[row][j][1]\n",
    "            SM[row][col] = score\n",
    "    # SM\n",
    "    #######################################################################\n",
    "    # # Get Top K list\n",
    "    # # Input: TFIDF Score Matrix SM, PageRank list R\n",
    "    # # Output: QAList(sorted order by TFIDF score * PageRank score)\n",
    "    #######################################################################\n",
    "    QAList = []\n",
    "    for it in UnionId_idx:\n",
    "        Id = it\n",
    "        UnionTFIDFScore = SM[...,UnionId_idx[it]].sum()\n",
    "        Uniontitle = id_title_dictionary[it] \n",
    "        PrankScore = R[N_idx[Id]][0]\n",
    "        QAList.append((Id, Uniontitle, UnionTFIDFScore, PrankScore))\n",
    "\n",
    "    def SortCriteria(item):\n",
    "        return item[2]*item[3]\n",
    "    QAList.sort(key= SortCriteria, reverse= True)\n",
    "\n",
    "    strFormat = '%-10s%-60s%-20s%-20s\\n'\n",
    "    strOut = strFormat % ('id', 'title', 'TF-IDF', 'PageRank')\n",
    "    iteration = 0;\n",
    "    for ans in QAList:\n",
    "        if iteration < 10:\n",
    "#             print(ans[0], ans[1], format(ans[2],\"10.2e\"), format(ans[3],\"10.2e\"))\n",
    "            strOut += strFormat %(ans[0], ans[1], format(ans[2],\"10.2e\"), format(ans[3],\"10.2e\"))\n",
    "        else:\n",
    "           break\n",
    "        iteration = iteration + 1\n",
    "    print(strOut)    \n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to mysql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection = pymysql.connect(host = 'localhost', \n",
    "#                             user = 'root',\n",
    "#                             password = 'root',\n",
    "#                             db = 'swyoo',\n",
    "#                             charset = 'utf8mb4')\n",
    "# try:\n",
    "#     cursor = connection.cursor()\n",
    "#     print(\"# tables:\", cursor.execute(\"show tables\"))\n",
    "#     sql = \"select * from wiki\"\n",
    "#     print(\"# row of wiki:\", cursor.execute(sql))\n",
    "#     result_wiki = cursor.fetchall()\n",
    "#     sql = \"select * from link\"\n",
    "#     print(\"# row of link:\", cursor.execute(sql))\n",
    "#     result_link = cursor.fetchall()\n",
    "#     print(\"[Sample of dataset] \")\n",
    "#     print(\" from wiki .... \")\n",
    "#     print(\" id: \", result_wiki[0][0])\n",
    "#     print(\" title:\", result_wiki[0][1])\n",
    "#     print(\" from link .... \")\n",
    "#     print(\" (from , to):\", result_link[0])\n",
    "# #     for row_data in result:\n",
    "# #         print(row_data)        \n",
    "# finally:\n",
    "#     connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import pandas as pd\n",
    "import nltk\n",
    "con = pymysql.connect(host = 'localhost', \n",
    "                            user = 'root',\n",
    "                            password = 'root',\n",
    "                            db = 'swyoo',\n",
    "                            charset = 'utf8mb4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = con.cursor()\n",
    "pd.read_sql(\"show tables\",con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing wiki table and Make InvertedIndex table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select * from wiki\"\n",
    "cursor.execute(sql)\n",
    "result_wiki = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test tokenization \n",
    "# tokens = nltk.word_tokenize(result_wiki[0][2])\n",
    "# fdist = nltk.FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make inverted index table \n",
    "# sql = \"create table InvertedIndex (term varchar(255) not null, id int(11) not null, freq int(11) not null)\"\n",
    "# cursor.execute(sql)\n",
    "\n",
    "# Clean inverted Index table \n",
    "# cursor.execute(\"delete from InvertedIndex\")\n",
    "# con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = \"select * from InvertedIndex\"\n",
    "# pd.read_sql(sql,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = \"insert into InvertedIndex (term,id,freq) values (%s,%s,%s)\"\n",
    "# for Doc in result_wiki:\n",
    "# #     print(type(Doc)) #tuple (id, doc_name, doc_script)\n",
    "#     tokens = nltk.word_tokenize(Doc[2].lower())\n",
    "#     fdist = nltk.FreqDist(tokens) # dictionary {term:freq, ... }\n",
    "#     for term, freq in fdist.items():\n",
    "#         cursor.execute(sql,(term, Doc[0], freq))\n",
    "# #     print(fdist)\n",
    "# con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = \"select * from InvertedIndex where term = 'man' order by id\"\n",
    "# pd.read_sql(sql,con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF score calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that given query word \"query\"\n",
    "query = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = \"select freq, id, term from InvertedIndex where term = '\"+ query +\"'order by id\"\n",
    "# pd.read_sql(sql,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select sum(freq),id from InvertedIndex where id in (select id from InvertedIndex where term = %s) group by id order by id\"\n",
    "cursor.execute(sql,query)\n",
    "NdInfo = cursor.fetchall()\n",
    "# # NdInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = \"select freq, id, term from InvertedIndex where term = '\"+ query +\"'order by id\"\n",
    "# pd.read_sql(sql,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select freq, id, term from InvertedIndex where term = %s order by id\"\n",
    "cursor.execute(sql,query)\n",
    "NdtInfo = cursor.fetchall()\n",
    "# #NdtInfo # tuple (freq, id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = \"select count(distinct id) from InvertedIndex where term = '\"+ query +\"'\"\n",
    "# pd.read_sql(sql,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select count(*) from InvertedIndex where term = %s\"\n",
    "cursor.execute(sql,query)\n",
    "Nt = cursor.fetchall()[0][0]\n",
    "# Nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(NdInfo))\n",
    "print(len(NdtInfo))\n",
    "print(Nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that given query word \"query\"\n",
    "sql = \"select sum(freq),id from InvertedIndex where id in (select id from InvertedIndex where term = %s) group by id order by id\"\n",
    "cursor.execute(sql,query)\n",
    "NdInfo = cursor.fetchall()\n",
    "\n",
    "sql = \"select freq, id, term from InvertedIndex where term = %s order by id\"\n",
    "cursor.execute(sql,query)\n",
    "NdtInfo = cursor.fetchall()\n",
    "\n",
    "sql = \"select count(*) from InvertedIndex where term = %s\"\n",
    "cursor.execute(sql,query)\n",
    "Nt = cursor.fetchall()[0][0]\n",
    "\n",
    "sql = \"select title,id from wiki where id in (select id from InvertedIndex where term = %s) order by id\"\n",
    "cursor.execute(sql,query)\n",
    "titles = cursor.fetchall()\n",
    "\n",
    "import math \n",
    "\n",
    "def TFIDFscore(Nd, Ndt, Nt):\n",
    "    return math.log1p(Ndt/Nd)*(1/Nt)\n",
    "\n",
    "TFIDF = []\n",
    "for i in range(len(NdtInfo)):\n",
    "    if NdInfo[i][1] == NdtInfo[i][1] & NdInfo[i][1] == titles[i][1]:\n",
    "        Nd = NdInfo[i][0]\n",
    "        Ndt = NdtInfo[i][0]\n",
    "        id = NdInfo[i][1]\n",
    "        title = titles[i][0]\n",
    "#         print(id,\" \",math.log1p(Ndt/Nd)*(1/Nt))\n",
    "#         TFIDF.append((id, math.log1p(Ndt/Nd)*(1/Nt)))\n",
    "        TFIDF.append((id, title, TFIDFscore(Nd, Ndt, Nt)))\n",
    "\n",
    "# def takeSecond(item):\n",
    "#     return item[2]\n",
    "\n",
    "# TFIDF.sort(key=takeSecond, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(TFIDF))\n",
    "print(len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration = 0;\n",
    "# for e in TFIDF:\n",
    "#     if iteration < len(TFIDF)/5:\n",
    "#         print(e)\n",
    "#     else:\n",
    "#        break\n",
    "#     iteration = iteration + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Ni for each\n",
    "sql = \"select id_from, count(*) as outgoing from link group by id_from order by id_from\"\n",
    "cursor.execute(sql)\n",
    "FromNiInfo = cursor.fetchall()\n",
    "\n",
    "Ni_dict = {}\n",
    "for idx, FromNi in enumerate(FromNiInfo):\n",
    "#     print(FromNi[0], FromNi[1])\n",
    "    id_from = FromNi[0]\n",
    "    Ni = FromNi[1]\n",
    "    Ni_dict[id_from] = Ni\n",
    "# Ni_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get N and id_all(sorted order) \n",
    "sql = \"select distinct id_from from link order by id_from\"\n",
    "cursor.execute(sql)\n",
    "SetOfFromInfo = cursor.fetchall()\n",
    "\n",
    "sql = \"select distinct id_to from link order by id_to\"\n",
    "cursor.execute(sql)\n",
    "SetOfToInfo = cursor.fetchall()\n",
    "\n",
    "SetOfFrom = set()\n",
    "SetOfTo = set()\n",
    "\n",
    "for idx, From in enumerate(SetOfFromInfo):\n",
    "#     print(type(From[0]))\n",
    "    SetOfFrom.add(From[0])\n",
    "    \n",
    "for idx, To in enumerate(SetOfToInfo):\n",
    "#     print(type(From[0]))\n",
    "    SetOfTo.add(To[0])\n",
    "\n",
    "print(len(SetOfFrom))\n",
    "print(len(SetOfTo))\n",
    "# print(len(SetOfFrom.intersection(SetOfTo)))\n",
    "# print(\"============\")\n",
    "# print(len(SetOfFrom) + len(SetOfTo) - len(SetOfFrom.intersection(SetOfTo)))\n",
    "id_all = sorted(SetOfFrom.union(SetOfTo))\n",
    "N = len(id_all)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get N_idx and N_idx_inverse; it means dictionary[Doc.id] = index of Transition Matrix or State Matrix    \n",
    "N_idx = {}\n",
    "N_idx_inverse = {}\n",
    "for idInfo, idx in enumerate(id_all):\n",
    "#     print(idx, idInfo)\n",
    "    N_idx[idx] = idInfo\n",
    "    N_idx_inverse[idInfo] = idx\n",
    "print(len(N_idx))\n",
    "print(len(N_idx_inverse))\n",
    "# N_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SateMatrix S; check whether existing from j to i link  \n",
    "S = np.zeros((N,N)) # from j to i info : S[i][j]\n",
    "# id_from = 17143\n",
    "# id_to = 2727051\n",
    "sql = \"select * from link order by id_from\"\n",
    "cursor.execute(sql)\n",
    "FromToInfo = np.array(cursor.fetchall())\n",
    "for fromto in FromToInfo:\n",
    "    id_to = fromto[1]\n",
    "    id_from = fromto[0]\n",
    "    S[N_idx[id_to]][N_idx[id_from]] = 1\n",
    "# S[N_idx[2727051]][N_idx[17143]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Transition Matrix M and Score Vector R \n",
    "M = np.zeros((N,N)) # from j to i info : M[i][j]\n",
    "# print(M.shape)\n",
    "for _, id_from in enumerate(sorted(SetOfFrom)):\n",
    "    for _, id_to in enumerate(id_all):\n",
    "        # if link id_from to id_to exists\n",
    "        if S[N_idx[id_to]][N_idx[id_from]] != 0:\n",
    "            M[N_idx[id_to]][N_idx[id_from]] = 1/Ni_dict[id_from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Error was found; N_idx have to be fixed(that is, link data should be fixed)\n",
    "# I found link dataset's error! duplicates exist ===>> Dataset is fixed!! \n",
    "for it in N_idx:\n",
    "    print(M[...,N_idx[it]].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PageRank Algorithm\n",
    "delta = 0.15\n",
    "elipslion = 1e-8\n",
    "# R = np.ones((N,1))*(1/N)\n",
    "R = np.ones((N,1))\n",
    "K = np.ones((N,1))*(delta/N)\n",
    "# R = delta * np.matmul(M,prevR) + K\n",
    "iteration = 0\n",
    "distance = 100\n",
    "while distance > elipslion:\n",
    "    print(\"iteration\", iteration, \"...\")\n",
    "    prevR = R\n",
    "    R = delta * np.matmul(M,R) + K\n",
    "    iteration = iteration + 1\n",
    "    distance = np.linalg.norm(R-prevR)\n",
    "    print(\"distance = \",np.linalg.norm(R-prevR))\n",
    "\n",
    "# Prank = []\n",
    "# for idx, r in enumerate(R):\n",
    "#     Prank.append((N_idx_inverse[idx], r[0]))\n",
    "\n",
    "# def takeSecond(item):\n",
    "#     return item[1]\n",
    "\n",
    "# Prank.sort(key= takeSecond, reverse= True)\n",
    "# Prank\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prank = []\n",
    "# for idx, r in enumerate(R):\n",
    "#     Prank.append((N_idx_inverse[idx], r[0]))\n",
    "# `\n",
    "# def takeSecond(item):\n",
    "#     return item[1]\n",
    "\n",
    "# Prank.sort(key= takeSecond, reverse= True)\n",
    "# # Prank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(R))\n",
    "print(len(TFIDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QAList = [] # DocScore = TFIDFScore * PrankScore\n",
    "for row in TFIDF:\n",
    "#      print(row)\n",
    "    PrankScore = R[N_idx[row[0]]][0]\n",
    "#     print(row[0], row[1], PrankScore, row[2])\n",
    "    QAList.append((row[0], row[1], PrankScore, row[2]))\n",
    "    \n",
    "def SortCriteria(item):\n",
    "    return item[2]*item[3]\n",
    "QAList.sort(key= SortCriteria, reverse= True)\n",
    "\n",
    "strFormat = '%-10s%-50s%-20s%-10s\\n'\n",
    "strOut = strFormat % ('id', 'title', 'TF-IDF', 'PageRank')\n",
    "iteration = 0;\n",
    "for ans in QAList:\n",
    "    if iteration < 10:\n",
    "#         print(ans[0], ans[1], ans[2], ans[3])\n",
    "        strOut += strFormat %(ans[0], ans[1], format(ans[2],\"10.2e\"), format(ans[3],\"10.2e\"))\n",
    "    else:\n",
    "       break\n",
    "    iteration = iteration + 1\n",
    "\n",
    "print(strOut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple words case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys = query.lower().split()\n",
    "querys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(querys)):\n",
    "#     print(i)\n",
    "for query in querys:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDFscore(Nd, Ndt, Nt):\n",
    "        return math.log1p(Ndt/Nd)*(1/Nt)\n",
    "\n",
    "TFIDFs_idx = {}\n",
    "TFIDFs_idx_inverse = {}\n",
    "TFIDFs = []\n",
    "iteration = 0\n",
    "for query in querys:\n",
    "    #######################################################################\n",
    "    # # TF-IDF Score calculation for one word \n",
    "    #######################################################################\n",
    "    sql = \"select sum(freq),id from InvertedIndex where id in (select id from InvertedIndex where term = %s) group by id order by id\"\n",
    "    cursor.execute(sql,query)\n",
    "    NdInfo = cursor.fetchall()\n",
    "\n",
    "    sql = \"select freq, id, term from InvertedIndex where term = %s order by id\"\n",
    "    cursor.execute(sql,query)\n",
    "    NdtInfo = cursor.fetchall()\n",
    "\n",
    "    sql = \"select count(*) from InvertedIndex where term = %s\"\n",
    "    cursor.execute(sql,query)\n",
    "    Nt = cursor.fetchall()[0][0]\n",
    "    \n",
    "#     print(len(NdInfo))\n",
    "#     print(len(NdtInfo))\n",
    "#     print(Nt)\n",
    "    TFIDF = []\n",
    "    for i in range(len(NdtInfo)):\n",
    "        if NdInfo[i][1] == NdtInfo[i][1]:\n",
    "            Nd = NdInfo[i][0]\n",
    "            Ndt = NdtInfo[i][0]\n",
    "            id = NdInfo[i][1]\n",
    "    #         print(id,\" \",math.log1p(Ndt/Nd)*(1/Nt))\n",
    "    #         TFIDF.append((id, math.log1p(Ndt/Nd)*(1/Nt)))\n",
    "            TFIDF.append((id, TFIDFscore(Nd, Ndt, Nt)))\n",
    "    TFIDFs.append(TFIDF)\n",
    "    TFIDFs_idx[query] = iteration\n",
    "    TFIDFs_idx_inverse[iteration] = query\n",
    "    iteration = iteration + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select id,title from wiki order by id\"\n",
    "cursor.execute(sql)\n",
    "id_title = cursor.fetchall()\n",
    "id_title_dictionary = {}\n",
    "for _, idtitle in enumerate(id_title):\n",
    "    v_id = idtitle[0]\n",
    "    v_title = idtitle[1]\n",
    "    id_title_dictionary[v_id] = v_title\n",
    "# id_title_dictionary[106791]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDFs[TFIDFs_idx[\"wanna\"]]\n",
    "# test = np.array([])\n",
    "# len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union\n",
    "TFIDFsetlist = []\n",
    "for query in querys:\n",
    "    temp = np.array(TFIDFs[TFIDFs_idx[query]])\n",
    "    if len(temp) == 0:\n",
    "        idsForOneQuery = temp.astype(int)\n",
    "    else:\n",
    "        idsForOneQuery = temp[...,0].astype(int)\n",
    "    TFIDFsetlist.append(set(idsForOneQuery))\n",
    "\n",
    "UnionId = []\n",
    "UnionId_idx = {}\n",
    "UnionId_idx_inverse = {}\n",
    "for TFIDFset in TFIDFsetlist:\n",
    "    print(len(UnionId)) \n",
    "    UnionId = list(set(UnionId)|set(TFIDFset))\n",
    "\n",
    "UnionId.sort()\n",
    "\n",
    "print(len(UnionId))\n",
    "iteration = 0;\n",
    "for idvalue in UnionId:\n",
    "    UnionId_idx[idvalue] = iteration\n",
    "    UnionId_idx_inverse[iteration] = idvalue\n",
    "    iteration = iteration + 1\n",
    "    \n",
    "# Get TFIDF Score Matrix SM\n",
    "SM = np.zeros((len(querys), len(UnionId)))\n",
    "print(SM.shape)\n",
    "for row in range(len(querys)):\n",
    "    LenOfcols = len(TFIDFs[row])\n",
    "#     print(LenOfcols)\n",
    "    for j in range(LenOfcols): # j means each query's index of id\n",
    "#         print(TFIDFs[row][j][0], TFIDFs[0][j][1], TFIDFs[0][j][2])  # \n",
    "        col = UnionId_idx[TFIDFs[row][j][0]]\n",
    "#         title = TFIDFs[row][j][1]\n",
    "        score = TFIDFs[row][j][1]\n",
    "        SM[row][col] = score\n",
    "# SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(UnionId_idx))\n",
    "QAList = []\n",
    "for it in UnionId_idx:\n",
    "    Id = it\n",
    "    UnionTFIDFScore = SM[...,UnionId_idx[it]].sum()\n",
    "    Uniontitle = id_title_dictionary[it] \n",
    "    PrankScore = R[N_idx[Id]][0]\n",
    "    QAList.append((Id, Uniontitle, UnionTFIDFScore, PrankScore))\n",
    "#     print(it)\n",
    "#     print(SM[...,UnionId_idx[it]].sum())\n",
    "\n",
    "def SortCriteria(item):\n",
    "    return item[2]*item[3]\n",
    "QAList.sort(key= SortCriteria, reverse= True)\n",
    "\n",
    "\n",
    "strFormat = '%-10s%-50s%-20s%-20s\\n'\n",
    "strOut = strFormat % ('id', 'title', 'TF-IDF', 'PageRank')\n",
    "iteration = 0;\n",
    "for ans in QAList:\n",
    "    if iteration < 10:\n",
    "#         print(ans[0], ans[1], ans[2], ans[3])\n",
    "        strOut += strFormat %(ans[0], ans[1], format(ans[2],\"10.2e\"), format(ans[3],\"10.2e\"))\n",
    "    else:\n",
    "       break\n",
    "    iteration = iteration + 1\n",
    "\n",
    "# strFormat = '%-10s%-50s%-20s%-20s%-20s\\n'\n",
    "# strOut = strFormat % ('id', 'title', 'TF-IDF', 'PageRank', 'TFIDF*PageRank' )\n",
    "# iteration = 0;\n",
    "# for ans in QAList:\n",
    "#     if iteration < 10:\n",
    "# #         print(ans[0], ans[1], ans[2], ans[3])\n",
    "#         strOut += strFormat %(ans[0], ans[1], format(ans[2],\"10.2e\"), format(ans[3],\"10.2e\"), format(ans[2]*ans[3],\"10.2e\"))\n",
    "#     else:\n",
    "#        break\n",
    "#     iteration = iteration + 1\n",
    "\n",
    "print(strOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UnionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "print(len(TFIDFs[0]))\n",
    "print(len(UnionId))\n",
    "j = 77\n",
    "print(TFIDFs[0][j][0], TFIDFs[0][j][1], TFIDFs[0][j][2])\n",
    "print(UnionId_idx[TFIDFs[0][j][0]])\n",
    "# UnionId\n",
    "# len(TFIDFs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.execute(\"drop table wiki\")\n",
    "# cursor.execute(\"drop table link\")\n",
    "# cursor.execute(\"drop table InvertedIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql(\"show tables\", con)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
